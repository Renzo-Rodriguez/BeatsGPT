{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637583ed-5077-403d-bfa2-0ecd5ff1c823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\", message=\"Attempting to use hipBLASLt on an unsupported architecture!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7bb29ad-8fc1-4647-bcfe-b629b83bdcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1892ce7a-e0dd-434a-b019-e0b3b8dc87da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Model hyperparameters\n",
    "LATENT_DIM = 64   # Size of latent space\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 1e-3\n",
    "EPOCHS = 50\n",
    "# Load processed mel spectrograms\n",
    "PROCESSED_DIR = \"/home/renzo/projects/stempalooza/processed_mel/\"\n",
    "\n",
    "os.environ[\"TORCH_USE_MIOPEN\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8c83b42-3361-425b-b230-4bca8631a8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# Dataset Class\n",
    "class MelDataset(Dataset):\n",
    "    def __init__(self, root_dir, device):\n",
    "        self.files = glob.glob(os.path.join(root_dir, \"**/*.npy\"), recursive=True)\n",
    "        self.device = device\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        mel_path = self.files[idx]\n",
    "        mel = torch.from_numpy(np.load(mel_path)).float()\n",
    "        # If mel is 2D (H, W), add channel dimension to get (1, H, W)\n",
    "        if len(mel.shape) == 2:\n",
    "            mel = mel.unsqueeze(0)\n",
    "        # Our expected shape is (1, 64, 16).\n",
    "        # Preprocessed spectrograms are (64, ~15) so we pad width dimension to 16.\n",
    "        if mel.shape[-1] < 16:\n",
    "            pad_amount = 16 - mel.shape[-1]\n",
    "            mel = F.pad(mel, (0, pad_amount), mode='constant', value=0)\n",
    "        if mel.shape[-1] > 16:\n",
    "            mel = mel[..., :16]\n",
    "        return mel.to(self.device)\n",
    "\n",
    "# ===============================\n",
    "# VAE Model\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim):\n",
    "        \"\"\"\n",
    "        input_dim: tuple, e.g. (64, 16)\n",
    "        latent_dim: size of latent space\n",
    "        \"\"\"\n",
    "        super(VAE, self).__init__()\n",
    "        # Encoder: using kernel_size=4, stride=2, padding=1\n",
    "        # Input shape: (1, 64, 16)\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=4, stride=2, padding=1),  # -> (32, 32, 8)\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=2, padding=1),  # -> (64, 16, 4)\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1), # -> (128, 8, 2)\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        # Calculate the flattened size (should be 128*8*2 = 2048)\n",
    "        self.conv_output_size = self._get_conv_output_size(input_dim)\n",
    "        # Latent space mapping\n",
    "        self.fc_mu = nn.Linear(self.conv_output_size, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(self.conv_output_size, latent_dim)\n",
    "        self.fc_decode = nn.Linear(latent_dim, self.conv_output_size)\n",
    "        # Decoder: reshape back to (128, 8, 2)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 1, kernel_size=3, stride=2, padding=1, output_padding=(1, 1)),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def _get_conv_output_size(self, input_dim):\n",
    "        # Create a dummy input on CPU for now (we later move model to device)\n",
    "        with torch.no_grad():\n",
    "            x = torch.zeros(1, 1, *input_dim, device=\"cpu\")\n",
    "            x = self.encoder(x)\n",
    "            print(f\"Output size after encoder (for input_dim {input_dim}): {x.shape}\")\n",
    "            return int(np.prod(x.size()))\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def forward(self, x):\n",
    "        #print('encoding')\n",
    "        # Ensure input is on the same device as model parameters.\n",
    "        x = x.to(next(self.parameters()).device)\n",
    "        x = self.encoder(x)\n",
    "        # Calling contiguous() can help with ROCm/MIOpen issues.\n",
    "        x = x.contiguous()\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        mu = self.fc_mu(x)\n",
    "        logvar = self.fc_logvar(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        x = self.fc_decode(z)\n",
    "        # Reshape back to (batch, 128, 8, 2)\n",
    "        x = x.view(-1, 128, 8, 2)\n",
    "        x = self.decoder(x)\n",
    "        return x, mu, logvar\n",
    "\n",
    "# ===============================\n",
    "# Loss function\n",
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    recon_loss = F.mse_loss(recon_x, x, reduction='sum')\n",
    "    kl_div = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return recon_loss + kl_div\n",
    "\n",
    "# ===============================\n",
    "# Training function\n",
    "def train(model, dataloader, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in dataloader:\n",
    "        batch = batch.to(device, dtype=torch.float32, non_blocking=True)\n",
    "        # Check if there are NaN or Inf values in the preprocessed data\n",
    "        if torch.isnan(batch).any() or torch.isinf(batch).any():\n",
    "            print(\"NaN or Inf detected in batch input!\")\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = model(batch)\n",
    "        loss = loss_function(recon_batch, batch, mu, logvar)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        # if torch.isnan(batch).any():\n",
    "        #     print(\"NaN detected in batch input!\")\n",
    "        # if torch.isnan(recon_batch).any():\n",
    "        #     print(\"NaN detected in reconstruction!\")\n",
    "        # if torch.isnan(mu).any() or torch.isnan(logvar).any():\n",
    "        #     print(\"NaN detected in mu or logvar!\")\n",
    "\n",
    "\n",
    "\n",
    "    return total_loss / len(dataloader.dataset)\n",
    "\n",
    "# ===============================\n",
    "# Main function\n",
    "def main():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    #device = torch.device(\"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    # Create dataset and dataloader\n",
    "    dataset = MelDataset(PROCESSED_DIR, device)\n",
    "    dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    # Input dimensions: (64, 16)\n",
    "    input_dim = (64, 16)\n",
    "    model = VAE(input_dim, LATENT_DIM).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    for epoch in range(EPOCHS):\n",
    "        loss = train(model, dataloader, optimizer, device)\n",
    "        print(f\"Epoch {epoch+1}/{EPOCHS}, Loss: {loss:.4f}\")\n",
    "    torch.save(model.state_dict(), \"vae_model.pth\")\n",
    "    print(\"Model saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e255f296-a48c-4407-86db-86186743459a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export MIOPEN_DEBUG_FIND_ONLY_SOLUTIONS=1\n",
    "!export HSA_OVERRIDE_GFX_VERSION=10.3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "538d177b-e327-4d9c-afd1-800d5df12495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n",
      "ROCm Available: 6.2.41134-65d174c3e\n",
      "Number of GPUs: 2\n",
      "GPU Name: AMD Radeon RX 7800 XT\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "print(\"ROCm Available:\", torch.version.hip)\n",
    "print(\"Number of GPUs:\", torch.cuda.device_count())\n",
    "print(\"GPU Name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU detected\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "896e88cb-36d7-4540-adaf-61a940777a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Output size after encoder (for input_dim (64, 16)): torch.Size([1, 128, 8, 2])\n",
      "NaN or Inf detected in batch input!\n",
      "NaN or Inf detected in batch input!\n",
      "NaN or Inf detected in batch input!\n",
      "NaN or Inf detected in batch input!\n",
      "NaN or Inf detected in batch input!\n",
      "NaN or Inf detected in batch input!\n",
      "NaN or Inf detected in batch input!\n",
      "NaN or Inf detected in batch input!\n",
      "NaN or Inf detected in batch input!\n",
      "NaN or Inf detected in batch input!\n",
      "NaN or Inf detected in batch input!\n",
      "NaN or Inf detected in batch input!\n",
      "NaN or Inf detected in batch input!\n",
      "NaN or Inf detected in batch input!\n",
      "NaN or Inf detected in batch input!\n",
      "NaN or Inf detected in batch input!\n",
      "NaN or Inf detected in batch input!\n",
      "NaN or Inf detected in batch input!\n",
      "NaN or Inf detected in batch input!\n",
      "NaN or Inf detected in batch input!\n",
      "NaN or Inf detected in batch input!\n",
      "NaN or Inf detected in batch input!\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[11], line 140\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    138\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mLEARNING_RATE)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(EPOCHS):\n\u001b[0;32m--> 140\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mEPOCHS\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    142\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(model\u001b[38;5;241m.\u001b[39mstate_dict(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvae_model.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[11], line 103\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, dataloader, optimizer, device)\u001b[0m\n\u001b[1;32m    101\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m    102\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 103\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Check if there are NaN or Inf values in the preprocessed data\u001b[39;49;00m\n",
      "File \u001b[0;32m~/projects/stempalooza/stem/lib/python3.13/site-packages/torch/utils/data/dataloader.py:708\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 708\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    710\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    711\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    712\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    713\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    714\u001b[0m ):\n",
      "File \u001b[0;32m~/projects/stempalooza/stem/lib/python3.13/site-packages/torch/utils/data/dataloader.py:764\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    762\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    763\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 764\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    765\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    766\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/projects/stempalooza/stem/lib/python3.13/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[11], line 13\u001b[0m, in \u001b[0;36mMelDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[1;32m     12\u001b[0m     mel_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfiles[idx]\n\u001b[0;32m---> 13\u001b[0m     mel \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmel_path\u001b[49m\u001b[43m)\u001b[49m)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m# If mel is 2D (H, W), add channel dimension to get (1, H, W)\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mel\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[0;32m~/projects/stempalooza/stem/lib/python3.13/site-packages/numpy/lib/_npyio_impl.py:488\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    485\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m.\u001b[39mopen_memmap(file, mode\u001b[38;5;241m=\u001b[39mmmap_mode,\n\u001b[1;32m    486\u001b[0m                                   max_header_size\u001b[38;5;241m=\u001b[39mmax_header_size)\n\u001b[1;32m    487\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 488\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_pickle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mpickle_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpickle_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mmax_header_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_header_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    492\u001b[0m     \u001b[38;5;66;03m# Try a pickle\u001b[39;00m\n\u001b[1;32m    493\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_pickle:\n",
      "File \u001b[0;32m~/projects/stempalooza/stem/lib/python3.13/site-packages/numpy/lib/format.py:816\u001b[0m, in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs, max_header_size)\u001b[0m\n\u001b[1;32m    814\u001b[0m     count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    815\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 816\u001b[0m     count \u001b[38;5;241m=\u001b[39m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmultiply\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint64\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;66;03m# Now read the actual data.\u001b[39;00m\n\u001b[1;32m    819\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype\u001b[38;5;241m.\u001b[39mhasobject:\n\u001b[1;32m    820\u001b[0m     \u001b[38;5;66;03m# The array contained Python objects. We need to unpickle the data.\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stem",
   "language": "python",
   "name": "stem"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
